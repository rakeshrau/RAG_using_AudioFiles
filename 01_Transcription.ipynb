{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc007338-2e00-421f-b56c-75ecd10e24f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-12 11:28:24--  http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\r\nResolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.82, 91.189.91.81, 185.125.190.36, ...\r\nConnecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.82|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1318204 (1.3M) [application/vnd.debian.binary-package]\r\nSaving to: ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb.1’\r\n\r\n\r          libssl1.1   0%[                    ]       0  --.-KB/s               \rlibssl1.1_1.1.1f-1u 100%[===================>]   1.26M  --.-KB/s    in 0.1s    \r\n\r\n2024-03-12 11:28:25 (11.2 MB/s) - ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb.1’ saved [1318204/1318204]\r\n\r\nSelecting previously unselected package libssl1.1:amd64.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 98474 files and directories currently installed.)\r\nPreparing to unpack libssl1.1_1.1.1f-1ubuntu2_amd64.deb ...\r\nUnpacking libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\r\nSetting up libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\r\ndebconf: unable to initialize frontend: Dialog\r\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\r\ndebconf: falling back to frontend: Readline\r\nProcessing triggers for libc-bin (2.35-0ubuntu3.6) ...\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
    "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1877b78d-168a-4dc5-9aa1-9d44b4f0f8b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting azure-cognitiveservices-speech==1.33.0\n  Downloading azure_cognitiveservices_speech-1.33.0-py3-none-manylinux1_x86_64.whl (3.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 18.0 MB/s eta 0:00:00\nInstalling collected packages: azure-cognitiveservices-speech\nSuccessfully installed azure-cognitiveservices-speech-1.33.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-speech==1.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec83c975-1000-43ce-9952-a5ebc61e3e22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -U azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "114c61d2-4b25-434e-b5d1-9e57baa448d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b3a5bc-1834-49f4-88c7-0c08360fe82f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96225ee7-c1fd-40f4-abfa-108deefe5ab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ['SPEECH_KEY'] = \"bb33fb8ed4e54099b7e845ca3508bf26\"\n",
    "os.environ['SPEECH_REGION'] = \"eastus2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25be457-6364-4707-8357-37c87c45a791",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb33fb8ed4e54099b7e845ca3508bf26\neastus2\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get('SPEECH_KEY'))\n",
    "print(os.environ.get('SPEECH_REGION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a6d5a8-8f3b-484c-b7f0-e33b4db71b96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Call back functions\n",
    "\n",
    "def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "    cancellation_details = evt.cancellation_details\n",
    "    print('Transciption session cancelled')\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Transciption session stopped')\n",
    "\n",
    "def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Transciption session started')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe6e324-ff83-4f87-bcb6-c3fca7529de6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_audio(filename):\n",
    "    transcriptions_list = []\n",
    "    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('SPEECH_KEY'), region=os.environ.get('SPEECH_REGION'))\n",
    "    speech_config.request_word_level_timestamps()\n",
    "    speech_config.speech_recognition_language=\"en-GB\"\n",
    "    speech_config.output_format = speechsdk.OutputFormat(1)\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=filename)\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    transcribing_stop = False\n",
    "\n",
    "    def conversation_transcriber_transcribed_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        transcriptions_list.append(evt)\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        #\"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        nonlocal transcribing_stop\n",
    "        transcribing_stop = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the conversation transcriber\n",
    "    conversation_transcriber.transcribed.connect(conversation_transcriber_transcribed_cb)\n",
    "    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "    # stop transcribing on either session stopped or canceled events\n",
    "    conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "    conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "    # Waits for completion.\n",
    "    while not transcribing_stop:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "    return transcriptions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "283dbe43-61ba-457d-bb74-7c758b709c1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_time_delta_to_string(time_delta):\n",
    "    hours, remainder = divmod(time_delta.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = time_delta.microseconds // 1000\n",
    "\n",
    "    formatted_time = f\"{hours:02}:{minutes:02}:{seconds:02}.{milliseconds:02}\"\n",
    "    \n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e51d5bd-5938-4510-abac-65558a89d4f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ticks_to_timedelta(tick):\n",
    "    microsecond = tick / 10\n",
    "    return datetime.timedelta(microseconds=microsecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c6622af-221e-4d65-b1a7-fdca9f121e4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_transcription_json(data):\n",
    "    string_data = []\n",
    "    for i in range(len(data)):\n",
    "        json_data = json.loads(data[i].result.json)\n",
    "        start_time = ticks_to_timedelta(json_data['Offset'])\n",
    "        end_time = ticks_to_timedelta(json_data['Offset'] + json_data['Duration'])\n",
    "        speaker = json_data['SpeakerId']\n",
    "        text = json_data['DisplayText']\n",
    "\n",
    "        start_time_string = convert_time_delta_to_string(start_time)\n",
    "        end_time_string = convert_time_delta_to_string(end_time)\n",
    "\n",
    "        string_data.append(f\"({start_time_string} - {end_time_string}) Speaker [{speaker}] : {text}\\n\")\n",
    "    \n",
    "    string = \"\".join(string_data)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5db0592e-0a9e-44fc-8e09-3c181ab223f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_27_2023_PA_PrEP_Consumer_Typing_Research_HCP_2.mp4\n09_27_2023_PCP_PrEP_Consumer_Typing_Research_HCP_1.mp4\n09_27_2023_PCP_PrEP_Consumer_Typing_Research_HCP_3.mp4\n09_29_2023_PA_PrEP_Consumer_Typing_Research_HCP__4.m4a\n09_29_2023_PA_PrEP_Consumer_Typing_Research_HCP__5.m4a\n10_02_2023_ObGyn_PrEP_Consumer_Typing_Research_HCP__7.m4a\n10_02_2023_ObGyn_PrEP_Consumer_Typing_Research__9.m4a\n10_02_2023_PA_PrEP_Consumer_Typing_Research_HCP__8.m4a\n10_02_2023_PCP_PrEP_Consumer_Typing_Research_HCP__10.m4a\n10_03_2023_ObGyn_PrEP_Consumer_Typing_Research__12.m4a\n10_03_2023_PCP_PrEP_Consumer_Typing_Research__13.m4a\n10_04_2023_NP_PrEP_Consumer_Typing_Research__15.m4a\n10_04_2023_ObGyn_PrEP_Consumer_Typing_Research__14.m4a\n10_05_2023_NP_PrEP_Consumer_Typing_Research__17.m4a\n10_05_2023_PCP_PrEP_Consumer_Typing_Research__16.m4a\nVaporetto_E_US_NAVIGATOR_5_Rosita_17Nov_5pmET_PatientAdvocate.wav\nVaporetto_E_US_PAT11_Rosita_8Nov_12pmET_Patient.wav\nVaporetto_E_US_PAT17_Rosita_13Nov_11amET_Patient.wav\nVaporetto_E_US_PAT18_Rosita_14_Nov_615pmET_NonUser.wav\nVaporetto_E_US_PAT19_Rosita_14Nov_11amET_PREP.wav\nVaporetto_E_US_PAT20_Rosita_14_Nov_1215pmET_Prep.wav\nVaporetto_E_US_PAT22_Rosita_15_Nov_4pmET_Patient.wav\nVaporetto_E_US_PAT23_Rosita_15_Nov_215pmET_Patient.wav\nVaporetto_E_US_PAT24_Rosita_16Nov_2PMEST_Patient.wav\nVaporetto_E_US_PAT29_Rosita_14Nov_5pmET_Nonuser.wav\nVaporetto_E_US_PAT30_Rosita_16_Nov_11amET_Patient.wav\nVaporetto_E_US_PAT31_Rosita_16Nov_530PMET_Patient.wav\nVaporetto_E_US_PAT32_Rosita_16_Nov_4pmET_NonUser.wav\nVaporetto_E_US_PAT33_Rosita_16Nov_7PMEST_Patient.wav\nVaporetto_E_US_PAT34_Rosita_9_Nov_145pmET_Patient.wav\nVaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER.wav\nVaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER__1_.wav\nVaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER__2_.wav\nVaporetto_E_US_PAT_02__Rosita_17Nov_2pmET_NON_USER.wav\nVaporetto_E_US_PAT_03__Rosita_17Nov_315pmET_PREP.wav\nVaporetto_E_US_PAT_16_Rosita_10_NOV_12PMET_NONUSER.wav\nVaporetto_E_US_PAT_26_Rosita_10_NOV_2PMET_NONUSER.wav\nVaporetto_E_US_TDI015_ROSITA_9_NOV_5PMET_Patient.wav\nVaporetto_E_US_TDI027_Emma_8_Nov_1045amET_Patient.wav\nVaporetto_E_US_TDI04_Rosita_7_Nov_2pmET_Patient.wav\nVaporetto_E_US_TDI06_Rosita_7Nov_1130amET_Patient.wav\nVaporetto_E_US_TDI07_Rosita_7Nov_1230pmET_Patient.wav\nVaporetto_E_US_TDI09_Rosita_7_Nov_330pmET_Patient.wav\nVaporetto_E_US_TDI101_Emma_8Nov_315pmET_PCP_GP_IM_FM.wav\nVaporetto_E_US_TDI104_Nishea_9Nov_6PMEST_PCP.wav\nVaporetto_E_US_TDI106_Nishea_10Nov_10amET_Nurse_Practitioner.wav\nVaporetto_E_US_TDI107_Nishea_14Nov_1145amET_NursePractitioner.wav\nVaporetto_E_US_TDI108_Nishea_16Nov_12PMEST_Infectious_Disease_Specialist_HIV_Specialist.wav\nVaporetto_E_US_TDI109_Nishea_16Nov_6pmET_PCP.wav\nVaporetto_E_US_TDI110_Nishea_14Nov_630pmET_InfectiousDiseaseSpecialist__HIV_Specialist.wav\nVaporetto_E_US_TDI110_Nishea_14Nov_630pmET_InfectiousDiseaseSpecialist__HIV_Specialist__1_.wav\nVaporetto_E_US_TDI111_Nishea_15Nov_330pmET_InfectiousDiseaseSpecialist_HIVSpecialist_PCP.wav\nVaporetto_E_US_TDI14_ROSITA_9_NOV_3PMET_PREP.wav\nVaporetto_E_US_TDI21_ROSITA_17_NOV_11AMET_NEVERPREP.wav\nVaporetto_E_US_TDI902_Rosita_15Nov_1pmET_Navigator.wav\nVaporetto_E_US_TDI904_Rosita_15Nov_515pmET_Navigator.wav\nVaporetto_E_US_TDI_105__Nishea_10Nov_1215pmET_PCP.wav\nVaporetto_E_US_TTDI903_Rosita_13Nov_130pmET_Navigator.wav\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/FileStore/Viiv_audio\"\n",
    "folder_path = \"test\"\n",
    "CALL_RECORDINGS = []\n",
    "for file in dbutils.fs.ls(base_path):\n",
    "  if file.isDir():\n",
    "    continue\n",
    "  CALL_RECORDINGS.append(os.path.splitext(file.name)[0])\n",
    "  print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46344db-c31f-415e-8d87-cd84a88cfe92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Vaporetto_E_US_NAVIGATOR_5_Rosita_17Nov_5pmET_PatientAdvocate as it already exists\nSkipping Vaporetto_E_US_PAT11_Rosita_8Nov_12pmET_Patient-1 as it already exists\nSkipping Vaporetto_E_US_PAT11_Rosita_8Nov_12pmET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT17_Rosita_13Nov_11amET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT18_Rosita_14_Nov_615pmET_NonUser as it already exists\nSkipping Vaporetto_E_US_PAT19_Rosita_14Nov_11amET_PREP as it already exists\nSkipping Vaporetto_E_US_PAT20_Rosita_14_Nov_1215pmET_Prep as it already exists\nSkipping Vaporetto_E_US_PAT22_Rosita_15_Nov_4pmET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT23_Rosita_15_Nov_215pmET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT24_Rosita_16Nov_2PMEST_Patient as it already exists\nSkipping Vaporetto_E_US_PAT29_Rosita_14Nov_5pmET_Nonuser as it already exists\nSkipping Vaporetto_E_US_PAT30_Rosita_16_Nov_11amET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT31_Rosita_16Nov_530PMET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT32_Rosita_16_Nov_4pmET_NonUser as it already exists\nSkipping Vaporetto_E_US_PAT33_Rosita_16Nov_7PMEST_Patient as it already exists\nSkipping Vaporetto_E_US_PAT34_Rosita_9_Nov_145pmET_Patient as it already exists\nSkipping Vaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER as it already exists\nSkipping Vaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER__1_ as it already exists\nSkipping Vaporetto_E_US_PAT35_Rosita_13Nov_4pmET_NONUSER__2_ as it already exists\nSkipping Vaporetto_E_US_PAT_02__Rosita_17Nov_2pmET_NON_USER as it already exists\nSkipping Vaporetto_E_US_PAT_03__Rosita_17Nov_315pmET_PREP-1 as it already exists\nSkipping Vaporetto_E_US_PAT_03__Rosita_17Nov_315pmET_PREP as it already exists\nSkipping Vaporetto_E_US_PAT_16_Rosita_10_NOV_12PMET_NONUSER as it already exists\nSkipping Vaporetto_E_US_PAT_26_Rosita_10_NOV_2PMET_NONUSER as it already exists\nSkipping Vaporetto_E_US_TDI015_ROSITA_9_NOV_5PMET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI027_Emma_8_Nov_1045amET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI04_Rosita_7_Nov_2pmET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI06_Rosita_7Nov_1130amET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI07_Rosita_7Nov_1230pmET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI09_Rosita_7_Nov_330pmET_Patient as it already exists\nSkipping Vaporetto_E_US_TDI101_Emma_8Nov_315pmET_PCP_GP_IM_FM as it already exists\nSkipping Vaporetto_E_US_TDI104_Nishea_9Nov_6PMEST_PCP as it already exists\nSkipping Vaporetto_E_US_TDI106_Nishea_10Nov_10amET_Nurse_Practitioner as it already exists\nSkipping Vaporetto_E_US_TDI107_Nishea_14Nov_1145amET_NursePractitioner as it already exists\nSkipping Vaporetto_E_US_TDI108_Nishea_16Nov_12PMEST_Infectious_Disease_Specialist_HIV_Specialist as it already exists\nSkipping Vaporetto_E_US_TDI109_Nishea_16Nov_6pmET_PCP as it already exists\nSkipping Vaporetto_E_US_TDI110_Nishea_14Nov_630pmET_InfectiousDiseaseSpecialist__HIV_Specialist as it already exists\nSkipping Vaporetto_E_US_TDI110_Nishea_14Nov_630pmET_InfectiousDiseaseSpecialist__HIV_Specialist__1_ as it already exists\nSkipping Vaporetto_E_US_TDI111_Nishea_15Nov_330pmET_InfectiousDiseaseSpecialist_HIVSpecialist_PCP as it already exists\nSkipping Vaporetto_E_US_TDI14_ROSITA_9_NOV_3PMET_PREP as it already exists\nSkipping Vaporetto_E_US_TDI21_ROSITA_17_NOV_11AMET_NEVERPREP as it already exists\nSkipping Vaporetto_E_US_TDI902_Rosita_15Nov_1pmET_Navigator as it already exists\nSkipping Vaporetto_E_US_TDI904_Rosita_15Nov_515pmET_Navigator as it already exists\nSkipping Vaporetto_E_US_TDI_105__Nishea_10Nov_1215pmET_PCP as it already exists\nSkipping Vaporetto_E_US_TTDI903_Rosita_13Nov_130pmET_Navigator as it already exists\n"
     ]
    }
   ],
   "source": [
    "base_path=\"/dbfs/FileStore/Viiv_audio\"\n",
    "input_relative_path = f\"{base_path}/00_audio/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/00_transcripts/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "        if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "            if file_name.endswith(\".wav\"):\n",
    "                name = os.path.splitext(file_name)[0]\n",
    "                \n",
    "\n",
    "                output_path = f'{output_relative_path}/{match}_transcript.txt'\n",
    "\n",
    "                if os.path.exists(output_path):\n",
    "                    print(f\"Skipping {name} as it already exists\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Processing {name}\")\n",
    "                    try:\n",
    "                        transcripts = transcribe_audio(f'{input_relative_path}/{file_name}')\n",
    "                        with open(output_path, \"w\") as f:\n",
    "                                f.write(process_transcription_json(transcripts))\n",
    "\n",
    "                    except Exception as err:\n",
    "                        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16b85ac-cecf-48d8-a28d-885d12966ab3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                        Version\n------------------------------ -------------\nabsl-py                        1.0.0\naccelerate                     0.25.0\naiohttp                        3.9.1\naiosignal                      1.3.1\nanyio                          3.5.0\nappdirs                        1.4.4\nargon2-cffi                    21.3.0\nargon2-cffi-bindings           21.2.0\nastor                          0.8.1\nasttokens                      2.0.5\nastunparse                     1.6.3\nasync-timeout                  4.0.3\nattrs                          22.1.0\naudioread                      3.0.1\nazure-cognitiveservices-speech 1.33.0\nazure-core                     1.29.1\nazure-cosmos                   4.3.1\nazure-storage-blob             12.19.0\nazure-storage-file-datalake    12.14.0\nbackcall                       0.2.0\nbcrypt                         3.2.0\nbeautifulsoup4                 4.11.1\nblack                          22.6.0\nbleach                         4.1.0\nblinker                        1.4\nblis                           0.7.11\nboto3                          1.24.28\nbotocore                       1.27.96\ncachetools                     5.3.2\ncatalogue                      2.0.10\ncategory-encoders              2.6.3\ncertifi                        2022.12.7\ncffi                           1.15.1\nchardet                        4.0.0\ncharset-normalizer             2.0.4\nclick                          8.0.4\ncloudpathlib                   0.16.0\ncloudpickle                    2.0.0\ncmdstanpy                      1.2.0\ncomm                           0.1.2\nconfection                     0.1.4\nconfigparser                   5.2.0\ncontourpy                      1.0.5\ncryptography                   39.0.1\ncycler                         0.11.0\ncymem                          2.0.8\nCython                         0.29.32\ndacite                         1.8.1\ndatabricks-automl-runtime      0.2.20\ndatabricks-cli                 0.18.0\ndatabricks-feature-engineering 0.2.0\ndatabricks-sdk                 0.1.6\ndataclasses-json               0.6.3\ndatasets                       2.15.0\ndbl-tempo                      0.1.26\ndbus-python                    1.2.18\ndebugpy                        1.6.7\ndecorator                      5.1.1\ndeepspeed                      0.12.4\ndefusedxml                     0.7.1\ndill                           0.3.6\ndiskcache                      5.6.3\ndistlib                        0.3.7\ndistro                         1.7.0\ndistro-info                    1.1+ubuntu0.2\ndocstring-to-markdown          0.11\nentrypoints                    0.4\nevaluate                       0.4.1\nexecuting                      0.8.3\nfacets-overview                1.1.1\nfastjsonschema                 2.19.1\nfasttext                       0.9.2\nfilelock                       3.9.0\nFlask                          2.2.5\nflatbuffers                    23.5.26\nfonttools                      4.25.0\nfrozenlist                     1.4.1\nfsspec                         2023.6.0\nfuture                         0.18.3\ngast                           0.4.0\ngitdb                          4.0.11\nGitPython                      3.1.27\ngoogle-api-core                2.15.0\ngoogle-auth                    2.21.0\ngoogle-auth-oauthlib           1.0.0\ngoogle-cloud-core              2.4.1\ngoogle-cloud-storage           2.11.0\ngoogle-crc32c                  1.5.0\ngoogle-pasta                   0.2.0\ngoogle-resumable-media         2.7.0\ngoogleapis-common-protos       1.62.0\ngreenlet                       2.0.1\ngrpcio                         1.48.2\ngrpcio-status                  1.48.1\ngunicorn                       20.1.0\ngviz-api                       1.10.0\nh5py                           3.7.0\nhjson                          3.1.0\nholidays                       0.38\nhorovod                        0.28.1\nhtmlmin                        0.1.12\nhttplib2                       0.20.2\nhuggingface-hub                0.19.4\nidna                           3.4\nImageHash                      4.3.1\nimbalanced-learn               0.11.0\nimportlib-metadata             4.11.3\nimportlib-resources            6.1.1\nipykernel                      6.25.0\nipython                        8.14.0\nipython-genutils               0.2.0\nipywidgets                     7.7.2\nisodate                        0.6.1\nitsdangerous                   2.0.1\njedi                           0.18.1\njeepney                        0.7.1\nJinja2                         3.1.2\njmespath                       0.10.0\njoblib                         1.2.0\njoblibspark                    0.5.1\njsonpatch                      1.33\njsonpointer                    2.4\njsonschema                     4.17.3\njupyter-client                 7.3.4\njupyter_core                   5.2.0\njupyter-server                 1.23.4\njupyterlab-pygments            0.1.2\njupyterlab-widgets             1.0.0\nkeras                          2.14.0\nkeyring                        23.5.0\nkiwisolver                     1.4.4\nlangchain                      0.0.348\nlangchain-core                 0.0.13\nlangcodes                      3.3.0\nlangsmith                      0.0.79\nlaunchpadlib                   1.10.16\nlazr.restfulclient             0.14.4\nlazr.uri                       1.0.6\nlazy_loader                    0.3\nlibclang                       15.0.6.1\nlibrosa                        0.10.1\nlightgbm                       4.1.0\nllvmlite                       0.39.1\nlxml                           4.9.1\nMako                           1.2.0\nMarkdown                       3.4.1\nMarkupSafe                     2.1.1\nmarshmallow                    3.20.2\nmatplotlib                     3.7.0\nmatplotlib-inline              0.1.6\nmccabe                         0.7.0\nmistune                        0.8.4\nml-dtypes                      0.2.0\nmlflow-skinny                  2.9.2\nmore-itertools                 8.10.0\nmpmath                         1.2.1\nmsgpack                        1.0.7\nmultidict                      6.0.4\nmultimethod                    1.10\nmultiprocess                   0.70.14\nmurmurhash                     1.0.10\nmypy-extensions                0.4.3\nnbclassic                      0.5.2\nnbclient                       0.5.13\nnbconvert                      6.5.4\nnbformat                       5.7.0\nnest-asyncio                   1.5.6\nnetworkx                       2.8.4\nninja                          1.11.1.1\nnltk                           3.7\nnodeenv                        1.8.0\nnotebook                       6.5.2\nnotebook_shim                  0.2.2\nnumba                          0.56.4\nnumpy                          1.23.5\noauthlib                       3.2.0\nopenai                         0.28.1\nopt-einsum                     3.3.0\npackaging                      23.2\npandas                         1.5.3\npandocfilters                  1.5.0\nparamiko                       2.9.2\nparso                          0.8.3\npathspec                       0.10.3\npatsy                          0.5.3\npetastorm                      0.12.1\npexpect                        4.8.0\nphik                           0.12.4\npickleshare                    0.7.5\nPillow                         9.4.0\npip                            22.3.1\nplatformdirs                   2.5.2\nplotly                         5.9.0\npluggy                         1.0.0\npmdarima                       2.0.4\npooch                          1.4.0\npreshed                        3.0.9\nprometheus-client              0.14.1\nprompt-toolkit                 3.0.36\nprophet                        1.1.5\nprotobuf                       4.24.0\npsutil                         5.9.0\npsycopg2                       2.9.3\nptyprocess                     0.7.0\npure-eval                      0.2.2\npy-cpuinfo                     9.0.0\npyarrow                        8.0.0\npyarrow-hotfix                 0.5\npyasn1                         0.4.8\npyasn1-modules                 0.2.8\npybind11                       2.11.1\npycparser                      2.21\npydantic                       1.10.6\npyflakes                       3.1.0\nPygments                       2.11.2\nPyGObject                      3.42.1\nPyJWT                          2.3.0\nPyNaCl                         1.5.0\npynvml                         11.5.0\npyodbc                         4.0.32\npyparsing                      3.0.9\npyright                        1.1.294\npyrsistent                     0.18.0\npytesseract                    0.3.10\npython-apt                     2.4.0+ubuntu3\npython-dateutil                2.8.2\npython-editor                  1.0.4\npython-lsp-jsonrpc             1.1.1\npython-lsp-server              1.8.0\npytoolconfig                   1.2.5\npytz                           2022.7\nPyWavelets                     1.4.1\nPyYAML                         6.0\npyzmq                          23.2.0\nregex                          2022.7.9\nrequests                       2.28.1\nrequests-oauthlib              1.3.1\nresponses                      0.18.0\nrope                           1.7.0\nrsa                            4.9\ns3transfer                     0.6.2\nsafetensors                    0.4.1\nscikit-learn                   1.1.1\nscipy                          1.10.0\nseaborn                        0.12.2\nSecretStorage                  3.3.1\nSend2Trash                     1.8.0\nsentence-transformers          2.2.2\nsentencepiece                  0.1.99\nsetuptools                     65.6.3\nshap                           0.44.0\nsimplejson                     3.17.6\nsix                            1.16.0\nslicer                         0.0.7\nsmart-open                     5.2.1\nsmmap                          5.0.0\nsniffio                        1.2.0\nsoundfile                      0.12.1\nsoupsieve                      2.3.2.post1\nsoxr                           0.3.7\nspacy                          3.7.2\nspacy-legacy                   3.0.12\nspacy-loggers                  1.0.5\nspark-tensorflow-distributor   1.0.0\nSQLAlchemy                     1.4.39\nsqlparse                       0.4.2\nsrsly                          2.4.8\nssh-import-id                  5.11\nstack-data                     0.2.0\nstanio                         0.3.0\nstatsmodels                    0.13.5\nsympy                          1.11.1\ntabulate                       0.8.10\ntangled-up-in-unicode          0.2.0\ntenacity                       8.1.0\ntensorboard                    2.14.1\ntensorboard-data-server        0.7.2\ntensorboard-plugin-profile     2.14.0\ntensorflow-cpu                 2.14.1\ntensorflow-estimator           2.14.0\ntensorflow-io-gcs-filesystem   0.35.0\ntermcolor                      2.4.0\nterminado                      0.17.1\nthinc                          8.2.2\nthreadpoolctl                  2.2.0\ntiktoken                       0.5.2\ntinycss2                       1.2.1\ntokenize-rt                    4.2.1\ntokenizers                     0.15.0\ntomli                          2.0.1\ntorch                          2.0.1+cpu\ntorchvision                    0.15.2+cpu\ntornado                        6.1\ntqdm                           4.64.1\ntraitlets                      5.7.1\ntransformers                   4.36.1\ntypeguard                      2.13.3\ntyper                          0.9.0\ntyping_extensions              4.4.0\ntyping-inspect                 0.9.0\nujson                          5.4.0\nunattended-upgrades            0.1\nurllib3                        1.26.14\nvirtualenv                     20.16.7\nvisions                        0.7.5\nwadllib                        1.3.6\nwasabi                         1.1.2\nwcwidth                        0.2.5\nweasel                         0.3.4\nwebencodings                   0.5.1\nwebsocket-client               0.58.0\nWerkzeug                       2.2.2\nwhatthepatch                   1.0.2\nwheel                          0.38.4\nwidgetsnbextension             3.6.1\nwordcloud                      1.9.3\nwrapt                          1.14.1\nxgboost                        1.7.6\nxxhash                         3.4.1\nyapf                           0.33.0\nyarl                           1.9.4\nydata-profiling                4.2.0\nzipp                           3.11.0\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4460d35e-59d5-4c9c-8fe1-dbcdf70db37e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01_Transcription",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
