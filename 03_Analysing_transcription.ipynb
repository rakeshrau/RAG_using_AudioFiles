{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b47552-e41f-44b8-927c-04901d90b220",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Processing Transcription Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc093bd-9054-4562-b528-363dcee4df2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "109ff41f-afd4-4dde-8ad2-ea5b3b663b50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cbf3a21-5fa3-4038-aaa9-12803eef5eb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: langchain in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (0.0.335)\nRequirement already satisfied: anyio<4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (3.7.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.9/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (2.0.23)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (0.6.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (1.33)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.9/site-packages (from langchain) (1.20.3)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.9/site-packages (from langchain) (1.9.2)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.9/site-packages (from langchain) (2.26.0)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (0.0.64)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (3.8.6)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.9/site-packages (from anyio<4.0->langchain) (3.2)\nRequirement already satisfied: exceptiongroup in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.1.3)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.3.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1d981333-0ddc-4bfe-8fdb-ab8ac0d64075/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2021.10.8)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: openai in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (1.2.4)\nRequirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.9/site-packages (from openai) (4.62.3)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from openai) (0.25.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from openai) (1.8.0)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1d981333-0ddc-4bfe-8fdb-ab8ac0d64075/lib/python3.9/site-packages (from openai) (4.5.0)\nRequirement already satisfied: anyio<4,>=3.5.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from openai) (3.7.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.9/site-packages (from openai) (1.9.2)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (3.2)\nRequirement already satisfied: exceptiongroup in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\nRequirement already satisfied: httpcore in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting typing-extensions==4.5.0\n  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nInstalling collected packages: typing-extensions\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.5.0\n    Uninstalling typing-extensions-4.5.0:\n      Successfully uninstalled typing-extensions-4.5.0\nSuccessfully installed typing-extensions-4.5.0\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: tiktoken in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (0.5.1)\nRequirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from tiktoken) (2023.10.3)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.9/site-packages (from tiktoken) (2.26.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install --force-reinstall typing-extensions==4.5.0\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80f2d4e5-de93-48da-9851-8d772b63b0f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e9bbbd-db62-46aa-a92d-8f385975df67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### OpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "### Callbacks\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "### Text Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "### Prompt Templates\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "\n",
    "### Python\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9c22982-41ff-4f3f-8b75-d3f2afad6de2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setting Environment Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bf9d2e-1fc2-478a-8cc2-cecf72fefc85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_EMBEDDING_DEPLOYMENT_NAME'] = \"t-e-ada-002\"\n",
    "os.environ['OPENAI_EMBEDDING_MODEL_NAME'] = \"text-embedding-ada-002\"\n",
    "os.environ['OPENAI_API_BASE'] = \"https://gsk-ds.openai.azure.com/\"\n",
    "os.environ['OPENAI_API_KEY'] = \"3599efaa37624ebbbe06dcb0fd571622\"\n",
    "os.environ['OPENAI_API_TYPE'] = \"Azure\"\n",
    "os.environ['OPENAI_API_VERSION'] = \"2023-07-01-preview\"\n",
    "os.environ['OPENAI_DEPLOYMENT_NAME'] = \"ds-gpt-4\"\n",
    "os.environ['OPENAI_MODEL_NAME'] = \"gpt-4\"\n",
    "os.environ['OPENAI_DEPLOYMENT_NAME_3_5'] = \"ds-gpt-35\"\n",
    "os.environ['OPENAI_MODEL_NAME_3_5'] = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc2ea7f-82bf-46b5-81a0-3ef2d601c56f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Instantiating Generative AI Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea3b4b7-4cf4-4b53-9e73-ebf1c5aa23df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Instantiating LLM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aaecfe4-7c59-49f3-9fa5-73774f5b4a5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/langchain/chat_models/azure_openai.py:152: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://gsk-ds.openai.azure.com/ to https://gsk-ds.openai.azure.com/openai.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/langchain/chat_models/azure_openai.py:159: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/langchain/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://gsk-ds.openai.azure.com/ to https://gsk-ds.openai.azure.com/openai.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/langchain/llms/openai.py:241: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/langchain/llms/openai.py:898: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Azure Chat LLM\n",
    "chat_llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Azure LLM\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=os.getenv(\"OPENAI_DEPLOYMENT_NAME\"),\n",
    "    model_name=os.getenv(\"OPENAI_MODEL_NAME\"),\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f75458a2-b26c-4ec6-9f76-651334bda268",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9c1dac-3bcc-48c5-ad08-5e44ba50a616",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a337e8ab-3249-489d-b0df-c99b4a630413",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a255abb5-99f4-4040-84ec-bb51961c2dcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Mapping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66dd0d5-ded7-4b2e-9c5e-d8a097cb7479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def check_status(row):\n",
    "    if \"GSO\" in row.values:\n",
    "        return \"GSO\"\n",
    "    elif \"Discussed\" in row.values:\n",
    "        return \"Discussed\"\n",
    "    else:\n",
    "        return \"Not Discussed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c06b4cc7-1cfd-4e9a-bd80-7d386c0d9ac7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ordering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d33a8d55-fb2f-435f-a5af-a085ea054a1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def order_by_suffix(df, column):\n",
    "    return (\n",
    "        df.assign(Index=df[column].str.split(\"_\").str[-1].astype(int))\n",
    "        .sort_values(by=[\"Index\"])\n",
    "        .drop(columns=[\"Index\"])\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab0ebb4-0f62-4ca0-8589-147de6f6e503",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Share of Voice Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f2e916-162f-4288-94e1-646a89039312",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_speaking_sessions(df):\n",
    "\n",
    "    df['speaking_duration'] = df['end_time'] - df['start_time']\n",
    "    df['words_per_section'] = df['text'].apply(lambda x: len(x.split( )))\n",
    "\n",
    "     # Initialize a list to store the aggregated results\n",
    "    aggregated_data = []\n",
    "\n",
    "    # Initialize variables to track the current speaker and total time\n",
    "    current_speaker = None\n",
    "    total_time = pd.Timedelta(0)\n",
    "    total_words = 0 \n",
    "\n",
    "    # Iterate through rows to aggregate time for the same speaker\n",
    "    for index, row in df.iterrows():\n",
    "        speaker = row['speaker']\n",
    "        speaking_duration = row['speaking_duration']\n",
    "        num_words = row['words_per_section']\n",
    "\n",
    "        if current_speaker is None:\n",
    "            current_speaker = speaker\n",
    "\n",
    "        if speaker == current_speaker:\n",
    "            total_time += speaking_duration\n",
    "            total_words += num_words\n",
    "            \n",
    "        else:\n",
    "            aggregated_data.append({'speaker': current_speaker, 'total_time': total_time, 'total_words': total_words})\n",
    "            current_speaker = speaker\n",
    "            total_time = speaking_duration\n",
    "            total_words = num_words\n",
    "\n",
    "    # Add the last speaker's total time\n",
    "    if current_speaker is not None:\n",
    "        aggregated_data.append({'speaker': current_speaker, 'total_time': total_time, 'total_words': total_words})\n",
    "\n",
    "    # Create a DataFrame from the aggregated data\n",
    "    result_df = pd.DataFrame(aggregated_data)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b09e9a27-5dbf-4e88-b85c-08b6614b4861",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_silence(transcript_df, threshold=0):\n",
    "    # Sort the dataframe by start time\n",
    "    transcript_df.sort_values(by=['start_time'], inplace=True)\n",
    "\n",
    "    # Initialize an empty list to store rows with gaps\n",
    "    rows_with_gaps = []\n",
    "\n",
    "    # Iterate through the rows in the dataframe\n",
    "    for index, row in transcript_df.iterrows():\n",
    "        # Check if there's a gap with the next row\n",
    "        if index < len(transcript_df) - 1:\n",
    "            current_end_time = row['end_time']\n",
    "            next_start_time = transcript_df.loc[index + 1, 'start_time']\n",
    "\n",
    "            # Calculate the time gap\n",
    "            if next_start_time > current_end_time:\n",
    "                time_gap = next_start_time - current_end_time\n",
    "            else:\n",
    "                time_gap = datetime.timedelta(seconds=0)\n",
    "\n",
    "            # If there's a gap, add a blank row\n",
    "            if time_gap > datetime.timedelta(seconds=threshold):  # Adjust the threshold as needed\n",
    "                blank_row = {\n",
    "                    'start_time': current_end_time,\n",
    "                    'end_time': next_start_time,\n",
    "                    'speaker': 'Silence',\n",
    "                    'text': ' '\n",
    "                }\n",
    "                rows_with_gaps.append(blank_row)\n",
    "\n",
    "    # Concatenate the original dataframe with the rows containing gaps\n",
    "    if rows_with_gaps:\n",
    "        transcript_df = pd.concat([transcript_df] + [pd.DataFrame(rows_with_gaps)])\n",
    "    \n",
    "    # Reset the index of the new dataframe\n",
    "    transcript_df.sort_values(by=['start_time'], inplace=True)\n",
    "    transcript_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba0691a-59a1-4e71-80c4-1f3b12203f2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def flatten_categorical_metrics(df, categorical_column, dictionary):\n",
    "    for metric in df.drop(categorical_column, axis=1).columns.to_list():\n",
    "        for speaker, value in zip(df[categorical_column],df[metric]):\n",
    "            new_col_name = f'{speaker} {metric}'\n",
    "            dictionary[new_col_name] = [value]\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75d17d47-953a-45b3-95ec-b4d6d6ba6231",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Defining Chat Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bea7ac4-a462-40c8-a4de-0987c1264b83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transcript Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2ba2710-e248-4bea-b481-9416d5a682d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "discussed_agreed_action = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                You are a helpful assistant that helps to understand if action planning topics were not discussed, discussed or agreed upon in sales calls.\n",
    "                - You will be given a transcript of sales calls and the action planning topics\n",
    "                - Your goal is to work out if a action planning topic was discussed or agreed upon in the sales calls\n",
    "\n",
    "                DEFINITIONS:\n",
    "                - Not Discussed: The action planning topic was not discussed in the sales call\n",
    "                - Discussed: The action planning topic was discussed in the sales call\n",
    "                - Agreed: The action planning topic was agreed upon in the sales call / the hcp already has the action planning topic in place or will be putting it in place\n",
    "\n",
    "                ACTION PLANNING TOPICS:\n",
    "                \t\n",
    "                1. Identify Eligible Patients: Searching and creating lists of eligible patients based on the NIP to be vaccinated with Shingrix\n",
    "                2. Recall Eligible Patients: Inviting patients to be vaccinated to the clinic (e.g., phone call, text message etc..)\n",
    "                3. Set up Shingrix Clinic: Setting up a dedicated clinic for patients to be vaccinated\n",
    "                4. Order Shingles Doses: Ordering Shingrix doses to the practice\n",
    "\n",
    "                TEMPLATE:\n",
    "                [Number] [Action planning topics] : [Verdict]\n",
    "                EXAMPLE:\n",
    "                1. Identify Eligible Patients: Searching and creating lists of eligible patients based on the NIP to be vaccinated with Shingrix : Discussed\n",
    "                2. Recall Eligible Patients: Inviting patients to be vaccinated to the clinic (e.g., phone call, text message etc..) : Discussed\n",
    "                3. Set up Shingrix Clinic: Setting up a dedicated clinic for patients to be vaccinated : Not Discussed\n",
    "                4. Order Shingles Doses: Ordering Shingrix doses to the practice : Agreed\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "find_how_many_times_key_topics_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                You are a helpful assistant that helps to understand if key message topics were conveyed in sales calls.\n",
    "                - You will be given a transcript of sales calls and the key message topics\n",
    "                - Your goal is to work out how many times each key message was conveyed by the REP\n",
    "                \n",
    "                IMPORTANT: IF THE PORTION OF TEXT HAS MULTIPLE KEY MESSAGES IN IT, COUNT THEM ALL\n",
    "                IMPORTANT: THERE IS NO LIMIT TO THE LENGTH OF A KEY MESSAGE\n",
    "                IMPORTANT: RETURN ALL THE KEY MESSAGE COUNTS IN THE SAME ORDER AS THE KEY MESSAGE TOPICS\n",
    "\n",
    "                KEY MESSAGE TOPICS:\n",
    "                \t\n",
    "                1. Shingles is a painful disease that can have serious and long-lasting complications\n",
    "                2. Post-herpetic neuralgia (PHN) affects up to 30% of patients ≥50 years old and is characterised by long-lasting nerve pain\n",
    "                3. 1 in 4 people in the UK will suffer from shingles in their lifetime\t\n",
    "                4. 90% of adults in the UK are infected with VZV, which causes shingles\t\n",
    "                5. The risk of shingles increases as immune system function declines\n",
    "                6. More than a rash, shingles and PHN can significantly impact a patient’s quality of life\n",
    "                7. Burden of Disease\n",
    "                8. National Immunisation Programme\n",
    "\n",
    "                TEMPLATE:\n",
    "                [Number] [Key Message/s] : [Count]\n",
    "                EXAMPLE:\n",
    "                1. Shingles is a painful disease that can have serious and long-lasting complications : 0\n",
    "                2. Post-herpetic neuralgia (PHN) affects up to 30% of patients ≥50 years old and is characterised by long-lasting nerve pain : 1\n",
    "                3. 1 in 4 people in the UK will suffer from shingles in their lifetime : 1\n",
    "                4. 90% of adults in the UK are infected with VZV, which causes shingles : 0\n",
    "                5. The risk of shingles increases as immune system function declines : 4\n",
    "                6. More than a rash, shingles and PHN can significantly impact a patient’s quality of life : 6\n",
    "                7. Burden of Disease : 2\n",
    "                8. National Immunisation Programme : 0\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "objection_raised = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                You are a helpful assistant that helps to understand if objections were raised in sales calls.\n",
    "                - You will be given a transcript of sales calls and the common objections that are raised in sales calls\n",
    "                - Your goal is to work out if the objection was raised in the sales calls\n",
    "\n",
    "                DEFINITIONS:\n",
    "                - Objection: A reason why a HCP might not want to prescribe a drug or is having difficulty prescribing a drug\n",
    "\n",
    "                OBJECTIONS:\n",
    "                \n",
    "                Objections to do with:\n",
    "                1. The NIP being confusing\n",
    "                2. Setting up Shingrix clinics\n",
    "                3. Patient recall challenges\n",
    "                4. Second dose compliance\n",
    "\n",
    "\n",
    "                TEMPLATE:\n",
    "                [Number] [Objection] : [Verdict]\n",
    "                EXAMPLE:\n",
    "                1. The NIP being confusing : True\n",
    "                2. Setting up Shingrix clinics : False\n",
    "                3. Patient recall challenges : True\n",
    "                4. Second dose compliance : True\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "consent_message_delivered = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                You are a helpful assistant that helps to understand if consent message was stated at the start of a sales call.\n",
    "                - You will be given a transcript of sales calls\n",
    "                - Your goal is to work out if the consent message was stated at the start of a sales call.\n",
    "\n",
    "                TEMPLATE:\n",
    "                [Consent] : [Verdict]\n",
    "                EXAMPLE:\n",
    "                Consent : True\n",
    "                Consent : False\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d2d898-7f89-4cbf-81da-86b7f6f65e6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59474b1e-76ff-49b2-9d13-f16e051a0030",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CALL_RECORDINGS = [\n",
    "    # \"Oct_20_2023_Call_01\",\n",
    "    # \"Oct_20_2023_Call_02\",\n",
    "    # \"Oct_20_2023_Call_03\",\n",
    "    # \"Oct_20_2023_Call_04\",\n",
    "    # \"Oct_20_2023_Call_05\",\n",
    "    # \"Oct_20_2023_Call_07\",\n",
    "    # \"Oct_20_2023_Call_08\",\n",
    "    # \"Oct_20_2023_Call_09\",\n",
    "    # \"Oct_20_2023_Call_10\",\n",
    "    # \"Oct_20_2023_Call_11\",\n",
    "    # \"Oct_20_2023_Call_12\",\n",
    "    # \"Oct_27_2023_Call_01\",\n",
    "    # \"Oct_27_2023_Call_02\",\n",
    "    # \"Oct_27_2023_Call_03\",\n",
    "    # \"Oct_27_2023_Call_04\",\n",
    "    # \"Oct_27_2023_Call_05\",\n",
    "    # \"Oct_27_2023_Call_06\",\n",
    "    # \"Oct_27_2023_Call_07\",\n",
    "    # \"Oct_27_2023_Call_08\",\n",
    "    # \"Oct_27_2023_Call_09\",\n",
    "    # \"Oct_27_2023_Call_10\",\n",
    "    # \"Oct_27_2023_Call_11\",\n",
    "    # \"Oct_27_2023_Call_12\",\n",
    "    # \"Nov_03_2023_Call_01\",\n",
    "    # \"Nov_03_2023_Call_02\",\n",
    "    # \"Nov_03_2023_Call_03\",\n",
    "    # \"Nov_03_2023_Call_04\",\n",
    "    # \"Nov_03_2023_Call_05\",\n",
    "    # \"Nov_03_2023_Call_06\",\n",
    "    # \"Nov_03_2023_Call_07\",\n",
    "    # \"Nov_03_2023_Call_08\",\n",
    "    # \"Nov_10_2023_Call_01\",\n",
    "    # \"Nov_10_2023_Call_02\",\n",
    "    # \"Nov_10_2023_Call_03\",\n",
    "    # \"Nov_10_2023_Call_04\",\n",
    "    # \"Nov_10_2023_Call_06\",\n",
    "    # \"Nov_17_2023_Call_01\",\n",
    "    # \"Nov_17_2023_Call_02\",\n",
    "    # \"Nov_17_2023_Call_03\",\n",
    "    # \"Nov_17_2023_Call_04\",\n",
    "    # \"Nov_17_2023_Call_05\",\n",
    "    # \"Nov_17_2023_Call_06\",\n",
    "    # \"Nov_17_2023_Call_07\",\n",
    "    # \"Nov_17_2023_Call_08\",\n",
    "    # \"Nov_24_2023_Call_01\",\n",
    "    # \"Nov_24_2023_Call_02\",\n",
    "    # \"Nov_24_2023_Call_03\",\n",
    "    # \"Nov_24_2023_Call_04\",\n",
    "    # \"Nov_24_2023_Call_05\",\n",
    "    # \"Nov_24_2023_Call_06\",\n",
    "    # \"Nov_24_2023_Call_07\",\n",
    "    # \"Dec_01_2023_Call_01\",\n",
    "    # \"Dec_01_2023_Call_02\",\n",
    "    # \"Dec_01_2023_Call_03\",\n",
    "    # \"Dec_01_2023_Call_04\",\n",
    "    # \"Dec_01_2023_Call_05\",\n",
    "    # \"Dec_01_2023_Call_06\",\n",
    "    # \"Dec_01_2023_Call_07\",\n",
    "    # \"Dec_01_2023_Call_08\",\n",
    "    # \"Dec_01_2023_Call_09\",\n",
    "    # \"Dec_01_2023_Call_10\",\n",
    "    # \"Dec_01_2023_Call_11\",\n",
    "    # \"Dec_01_2023_Call_12\",\n",
    "    # \"Dec_01_2023_Call_13\",\n",
    "    # \"Dec_01_2023_Call_15\",\n",
    "    # \"Dec_08_2023_Call_01\",\n",
    "    # \"Dec_08_2023_Call_02\",\n",
    "    # \"Dec_08_2023_Call_03\",\n",
    "    # \"Dec_08_2023_Call_04\",\n",
    "    # \"Dec_08_2023_Call_05\",\n",
    "    # \"Dec_08_2023_Call_06\",\n",
    "    # \"Dec_08_2023_Call_07\",\n",
    "    # \"Dec_08_2023_Call_08\",\n",
    "    # \"Dec_08_2023_Call_09\",\n",
    "    # \"Dec_08_2023_Call_10\",\n",
    "    # \"Dec_08_2023_Call_11\",\n",
    "    # \"Dec_08_2023_Call_12\",\n",
    "    # \"Dec_08_2023_Call_13\",\n",
    "    # \"Dec_15_2023_Call_01\",\n",
    "    # \"Dec_15_2023_Call_02\",\n",
    "    # \"Dec_15_2023_Call_03\",\n",
    "    # \"Dec_15_2023_Call_04\",\n",
    "    # \"Dec_15_2023_Call_05\",\n",
    "    # \"Dec_15_2023_Call_06\",\n",
    "    # \"Dec_15_2023_Call_07\",\n",
    "    # \"Dec_15_2023_Call_08\",\n",
    "    # \"Dec_15_2023_Call_09\",\n",
    "    # \"Dec_15_2023_Call_10\",\n",
    "    # \"Dec_22_2023_Call_01\",\n",
    "    # \"Dec_22_2023_Call_02\",\n",
    "    # \"Dec_22_2023_Call_03\",\n",
    "    # \"Dec_22_2023_Call_04\",\n",
    "    # \"Dec_22_2023_Call_05\",\n",
    "    # \"Dec_22_2023_Call_06\",\n",
    "    # \"Dec_22_2023_Call_07\",\n",
    "    # \"Dec_22_2023_Call_08\",\n",
    "    # \"Dec_22_2023_Call_09\",\n",
    "    # \"Jan_12_2024_Call_01\",\n",
    "    # \"Jan_12_2024_Call_02\",\n",
    "    \"Jan_12_2024_Call_03\",\n",
    "    \"Jan_12_2024_Call_04\",\n",
    "    \"Jan_12_2024_Call_05\",\n",
    "    \"Jan_12_2024_Call_06\",\n",
    "    \"Jan_12_2024_Call_07\",\n",
    "    \"Jan_12_2024_Call_08\",\n",
    "    \"Jan_12_2024_Call_09\",\n",
    "    # \"Jan_19_2024_Call_01\",\n",
    "    # \"Jan_19_2024_Call_02\",\n",
    "    # \"Jan_19_2024_Call_03\",\n",
    "    # \"Jan_19_2024_Call_04\",\n",
    "    # \"Jan_19_2024_Call_05\",\n",
    "    # \"Jan_19_2024_Call_06\",\n",
    "    # \"Jan_19_2024_Call_07\",\n",
    "    # \"Jan_19_2024_Call_08\",\n",
    "    # \"Jan_19_2024_Call_09\",\n",
    "    # \"Jan_19_2024_Call_10\",\n",
    "    # \"Jan_19_2024_Call_11\",\n",
    "    # \"Jan_19_2024_Call_12\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/dbfs/FileStore/smart_call_insights/max\"\n",
    "folder_path = \"jan_12_2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c92537-df4f-4add-823b-8f81e4c9ce61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Action Points Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd94242f-0055-4267-9d17-c19fb87bd7d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Nov03_callrecording_01_sectioned\nTokens Used: 8998, Prompt Tokens: 8788, Completion Tokens: 210, Successful Requests: 2 \nTotal Cost (USD): $0.28\nTime Taken: 12.18 seconds\nProcessing Nov03_callrecording_02_sectioned\nTokens Used: 2230, Prompt Tokens: 2125, Completion Tokens: 105, Successful Requests: 1 \nTotal Cost (USD): $0.07\nTime Taken: 7.65 seconds\nProcessing Nov03_callrecording_03_sectioned\nTokens Used: 3110, Prompt Tokens: 3004, Completion Tokens: 106, Successful Requests: 1 \nTotal Cost (USD): $0.1\nTime Taken: 5.96 seconds\nProcessing Nov03_callrecording_04_sectioned\nTokens Used: 5203, Prompt Tokens: 4990, Completion Tokens: 213, Successful Requests: 2 \nTotal Cost (USD): $0.16\nTime Taken: 16.36 seconds\nProcessing Nov03_callrecording_05_sectioned\nTokens Used: 5671, Prompt Tokens: 5458, Completion Tokens: 213, Successful Requests: 2 \nTotal Cost (USD): $0.18\nTime Taken: 14.48 seconds\nProcessing Nov03_callrecording_06_sectioned\nTokens Used: 8875, Prompt Tokens: 8666, Completion Tokens: 209, Successful Requests: 2 \nTotal Cost (USD): $0.27\nTime Taken: 16.37 seconds\nProcessing Nov03_callrecording_07_sectioned\nTokens Used: 1638, Prompt Tokens: 1530, Completion Tokens: 108, Successful Requests: 1 \nTotal Cost (USD): $0.05\nTime Taken: 11.48 seconds\nProcessing Nov03_callrecording_08_sectioned\nTokens Used: 3760, Prompt Tokens: 3655, Completion Tokens: 105, Successful Requests: 1 \nTotal Cost (USD): $0.12\nTime Taken: 7.88 seconds\n"
     ]
    }
   ],
   "source": [
    "input_relative_path = f\"{base_path}/06_section/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/07_action_plan_verdict/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "        with open(f\"{input_relative_path}/{file_name}\", \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        name = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        chunked_text = text_splitter.create_documents([text])\n",
    "        action_plan_verdict = dict()\n",
    "        action_plan_verdict[\"Call Name\"] = match\n",
    "        action_plan_verdict[\"Call Number\"]= int(match.split(\"_\")[-1])\n",
    "        date = \"_\".join(match.split(\"_\")[:3])\n",
    "        call_datetime = dt.strptime(date, \"%b_%d_%Y\")\n",
    "        action_plan_verdict[\"Call Day\"] = call_datetime.strftime(\"%d\")\n",
    "        action_plan_verdict[\"Call Month\"] = call_datetime.strftime(\"%m\")\n",
    "        action_plan_verdict[\"Call Year\"] = call_datetime.strftime(\"%Y\")\n",
    "        total_tokens = 0\n",
    "        prompt_tokens = 0\n",
    "        completion_tokens = 0\n",
    "        successful_requests = 0\n",
    "        total_cost = 0\n",
    "        for i, chunk in enumerate(chunked_text):\n",
    "            with get_openai_callback() as cb:\n",
    "                output = chat_llm(\n",
    "                    discussed_agreed_action.format_messages(text=chunk.page_content)\n",
    "                )\n",
    "                # print(output.content)\n",
    "                pattern = r\"\\d+. (.+): (Discussed|Agreed|Not Discussed)\"\n",
    "\n",
    "                count_list = output.content.split(\"\\n\")\n",
    "\n",
    "                for category in count_list:\n",
    "                    re_match = re.findall(pattern, category)[0]\n",
    "\n",
    "                    action_plan = re_match[0].strip().split(\":\")[0]\n",
    "                    verdict = re_match[1].strip()\n",
    "\n",
    "                    if action_plan_verdict.get(action_plan) is None:\n",
    "                        action_plan_verdict[action_plan] = verdict\n",
    "                    elif action_plan_verdict.get(action_plan) == \"Not Discussed\":\n",
    "                        if verdict == \"Discussed\":\n",
    "                            action_plan_verdict[action_plan] = \"Discussed\"\n",
    "                        elif verdict == \"Agreed\":\n",
    "                            action_plan_verdict[action_plan] = \"Agreed\"\n",
    "                    elif action_plan_verdict.get(action_plan) == \"Discussed\":\n",
    "                        if verdict == \"Agreed\":\n",
    "                            action_plan_verdict[action_plan] = \"Agreed\"\n",
    "                    elif action_plan_verdict.get(action_plan) == \"Agreed\":\n",
    "                        pass\n",
    "\n",
    "                # Costs and Tokens\n",
    "                total_tokens += cb.total_tokens\n",
    "                prompt_tokens += cb.prompt_tokens\n",
    "                completion_tokens += cb.completion_tokens\n",
    "                successful_requests += cb.successful_requests\n",
    "                total_cost += cb.total_cost\n",
    "\n",
    "        df = pd.DataFrame(action_plan_verdict, index=[0])\n",
    "        df = df.replace({\"Agreed\": \"GSO\"})\n",
    "        df[\"Selling Outcome\"] = df.apply(check_status, axis=1)\n",
    "        df.to_csv(\n",
    "            f\"{output_relative_path}/{match}_action_plan_verdict.csv\", index=False\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Tokens Used: {total_tokens}, Prompt Tokens: {prompt_tokens}, Completion Tokens: {completion_tokens}, Successful Requests: {successful_requests} \\nTotal Cost (USD): ${round(total_cost, 2)}\"\n",
    "        )\n",
    "        print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "156628e4-2edc-4deb-88c6-e27668c190e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Analysing Key Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22ebdcea-700c-442e-acb2-82c1e19f583e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Nov03_callrecording_01_sectioned\nTokens Used: 9326, Prompt Tokens: 8992, Completion Tokens: 334, Successful Requests: 2 \nTotal Cost (USD): $0.29\nTime Taken: 24.8 seconds\nProcessing Nov03_callrecording_02_sectioned\nTokens Used: 2394, Prompt Tokens: 2227, Completion Tokens: 167, Successful Requests: 1 \nTotal Cost (USD): $0.08\nTime Taken: 11.63 seconds\nProcessing Nov03_callrecording_03_sectioned\nTokens Used: 3273, Prompt Tokens: 3106, Completion Tokens: 167, Successful Requests: 1 \nTotal Cost (USD): $0.1\nTime Taken: 8.81 seconds\nProcessing Nov03_callrecording_04_sectioned\nTokens Used: 5528, Prompt Tokens: 5194, Completion Tokens: 334, Successful Requests: 2 \nTotal Cost (USD): $0.18\nTime Taken: 25.33 seconds\nProcessing Nov03_callrecording_05_sectioned\nTokens Used: 5996, Prompt Tokens: 5662, Completion Tokens: 334, Successful Requests: 2 \nTotal Cost (USD): $0.19\nTime Taken: 19.91 seconds\nProcessing Nov03_callrecording_06_sectioned\nTokens Used: 9204, Prompt Tokens: 8870, Completion Tokens: 334, Successful Requests: 2 \nTotal Cost (USD): $0.29\nTime Taken: 18.92 seconds\nProcessing Nov03_callrecording_07_sectioned\nTokens Used: 1799, Prompt Tokens: 1632, Completion Tokens: 167, Successful Requests: 1 \nTotal Cost (USD): $0.06\nTime Taken: 10.3 seconds\nProcessing Nov03_callrecording_08_sectioned\nTokens Used: 3924, Prompt Tokens: 3757, Completion Tokens: 167, Successful Requests: 1 \nTotal Cost (USD): $0.12\nTime Taken: 15.8 seconds\n"
     ]
    }
   ],
   "source": [
    "input_relative_path = f\"{base_path}/06_section/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/07_key_topics_conveyed/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "        with open(f\"{input_relative_path}/{file_name}\", \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        name = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        chunked_text = text_splitter.create_documents([text])\n",
    "        key_topic_count = dict()\n",
    "        key_topic_count[\"Call Name\"] = match\n",
    "        key_topic_count[\"Call Number\"]= int(match.split(\"_\")[-1])\n",
    "        date = \"_\".join(match.split(\"_\")[:3])\n",
    "        call_datetime = dt.strptime(date, \"%b_%d_%Y\")\n",
    "        key_topic_count[\"Call Day\"] = call_datetime.strftime(\"%d\")\n",
    "        key_topic_count[\"Call Month\"] = call_datetime.strftime(\"%m\")\n",
    "        key_topic_count[\"Call Year\"] = call_datetime.strftime(\"%Y\")\n",
    "        total_tokens = 0\n",
    "        prompt_tokens = 0\n",
    "        completion_tokens = 0\n",
    "        successful_requests = 0\n",
    "        total_cost = 0\n",
    "        for i, chunk in enumerate(chunked_text):\n",
    "            with get_openai_callback() as cb:\n",
    "                output = chat_llm(\n",
    "                    find_how_many_times_key_topics_template.format_messages(\n",
    "                        text=chunk.page_content\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                pattern = r\"\\d+.(.+): (\\d+)\"\n",
    "\n",
    "                count_list = output.content.split(\"\\n\")\n",
    "\n",
    "                for category in count_list:\n",
    "                    re_match = re.findall(pattern, category)[0]\n",
    "\n",
    "                    key_topic = re_match[0].strip()\n",
    "                    count = int(re_match[1].strip())\n",
    "\n",
    "                    if key_topic_count.get(key_topic):\n",
    "                        key_topic_count[key_topic] += count\n",
    "                    else:\n",
    "                        key_topic_count[key_topic] = count\n",
    "\n",
    "                # Costs and Tokens\n",
    "                total_tokens += cb.total_tokens\n",
    "                prompt_tokens += cb.prompt_tokens\n",
    "                completion_tokens += cb.completion_tokens\n",
    "                successful_requests += cb.successful_requests\n",
    "                total_cost += cb.total_cost\n",
    "\n",
    "        df = pd.DataFrame(key_topic_count, index=[0])\n",
    "        df.to_csv(\n",
    "            f\"{output_relative_path}/{match}_key_topic_count.csv\", index=False\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Tokens Used: {total_tokens}, Prompt Tokens: {prompt_tokens}, Completion Tokens: {completion_tokens}, Successful Requests: {successful_requests} \\nTotal Cost (USD): ${round(total_cost, 2)}\"\n",
    "        )\n",
    "        print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a9db576-ceec-4592-8fe8-8889aa30a07d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Objection Raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d023253a-7a46-41b3-adc9-50048544443e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Nov03_callrecording_01_sectioned\nTokens Used: 8496, Prompt Tokens: 8424, Completion Tokens: 72, Successful Requests: 2 \nTotal Cost (USD): $0.26\nTime Taken: 7.56 seconds\nProcessing Nov03_callrecording_02_sectioned\nTokens Used: 1979, Prompt Tokens: 1943, Completion Tokens: 36, Successful Requests: 1 \nTotal Cost (USD): $0.06\nTime Taken: 3.48 seconds\nProcessing Nov03_callrecording_03_sectioned\nTokens Used: 2858, Prompt Tokens: 2822, Completion Tokens: 36, Successful Requests: 1 \nTotal Cost (USD): $0.09\nTime Taken: 2.85 seconds\nProcessing Nov03_callrecording_04_sectioned\nTokens Used: 4698, Prompt Tokens: 4626, Completion Tokens: 72, Successful Requests: 2 \nTotal Cost (USD): $0.14\nTime Taken: 6.61 seconds\nProcessing Nov03_callrecording_05_sectioned\nTokens Used: 5166, Prompt Tokens: 5094, Completion Tokens: 72, Successful Requests: 2 \nTotal Cost (USD): $0.16\nTime Taken: 4.79 seconds\nProcessing Nov03_callrecording_06_sectioned\nTokens Used: 8374, Prompt Tokens: 8302, Completion Tokens: 72, Successful Requests: 2 \nTotal Cost (USD): $0.25\nTime Taken: 7.28 seconds\nProcessing Nov03_callrecording_07_sectioned\nTokens Used: 1384, Prompt Tokens: 1348, Completion Tokens: 36, Successful Requests: 1 \nTotal Cost (USD): $0.04\nTime Taken: 7.37 seconds\nProcessing Nov03_callrecording_08_sectioned\nTokens Used: 3509, Prompt Tokens: 3473, Completion Tokens: 36, Successful Requests: 1 \nTotal Cost (USD): $0.11\nTime Taken: 1.92 seconds\n"
     ]
    }
   ],
   "source": [
    "input_relative_path = f\"{base_path}/06_section/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/07_objection_raised/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "        with open(f\"{input_relative_path}/{file_name}\", \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        name = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        chunked_text = text_splitter.create_documents([text])\n",
    "        objection_verdict = dict()\n",
    "        objection_verdict[\"Call Name\"] = match\n",
    "        objection_verdict[\"Call Number\"]= int(match.split(\"_\")[-1])\n",
    "        date = \"_\".join(match.split(\"_\")[:3])\n",
    "        call_datetime = dt.strptime(date, \"%b_%d_%Y\")\n",
    "        objection_verdict[\"Call Day\"] = call_datetime.strftime(\"%d\")\n",
    "        objection_verdict[\"Call Month\"] = call_datetime.strftime(\"%m\")\n",
    "        objection_verdict[\"Call Year\"] = call_datetime.strftime(\"%Y\")\n",
    "        total_tokens = 0\n",
    "        prompt_tokens = 0\n",
    "        completion_tokens = 0\n",
    "        successful_requests = 0\n",
    "        total_cost = 0\n",
    "        for i, chunk in enumerate(chunked_text):\n",
    "            with get_openai_callback() as cb:\n",
    "                output = chat_llm(\n",
    "                    objection_raised.format_messages(text=chunk.page_content)\n",
    "                )\n",
    "                pattern = r\"\\d+. (.+): (True|False)\"\n",
    "\n",
    "                count_list = output.content.split(\"\\n\")\n",
    "\n",
    "                for category in count_list:\n",
    "                    re_match = re.findall(pattern, category)[0]\n",
    "\n",
    "                    key_message = re_match[0].strip()\n",
    "                    verdict = re_match[1].strip()\n",
    "\n",
    "                    if objection_verdict.get(key_message) is None:\n",
    "                        objection_verdict[key_message] = verdict\n",
    "                    elif objection_verdict.get(key_message) == \"False\":\n",
    "                        if verdict == \"True\":\n",
    "                            objection_verdict[key_message] = \"True\"\n",
    "                    elif objection_verdict.get(key_message) == \"True\":\n",
    "                        pass\n",
    "\n",
    "                # Costs and Tokens\n",
    "                total_tokens += cb.total_tokens\n",
    "                prompt_tokens += cb.prompt_tokens\n",
    "                completion_tokens += cb.completion_tokens\n",
    "                successful_requests += cb.successful_requests\n",
    "                total_cost += cb.total_cost\n",
    "\n",
    "        df = pd.DataFrame(objection_verdict, index=[0])\n",
    "        df = df.replace({\"True\": \"Objection Raised\", \"False\": \"Objection Not Raised\"})\n",
    "        df.to_csv(\n",
    "            f\"{output_relative_path}/{match}_objection_verdict.csv\", index=False\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Tokens Used: {total_tokens}, Prompt Tokens: {prompt_tokens}, Completion Tokens: {completion_tokens}, Successful Requests: {successful_requests} \\nTotal Cost (USD): ${round(total_cost, 2)}\"\n",
    "        )\n",
    "        print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f0e4fad-dc75-4fec-a2eb-6dfb6cc3f5d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Share of Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269b5291-78ce-42f3-b6b0-273b54cc239a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Oct20_callrecording_01_sov\nTime Taken: 0.16 seconds\nProcessing Oct20_callrecording_02_sov\nTime Taken: 0.11 seconds\nProcessing Oct20_callrecording_03_sov\nTime Taken: 0.09 seconds\nProcessing Oct20_callrecording_04_sov\nTime Taken: 0.35 seconds\nProcessing Oct20_callrecording_05_sov\nTime Taken: 0.33 seconds\nProcessing Oct20_callrecording_07_sov\nTime Taken: 0.19 seconds\nProcessing Oct20_callrecording_08_sov\nTime Taken: 0.11 seconds\nProcessing Oct20_callrecording_09_sov\nTime Taken: 0.09 seconds\nProcessing Oct20_callrecording_10_sov\nTime Taken: 0.21 seconds\nProcessing Oct20_callrecording_11_sov\nTime Taken: 0.23 seconds\nProcessing Oct20_callrecording_12_sov\nTime Taken: 0.15 seconds\n"
     ]
    }
   ],
   "source": [
    "input_relative_path = f\"{base_path}/05_share_of_voice/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/07_share_of_voice/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "        df = pd.read_csv(os.path.join(input_relative_path, file_name))\n",
    "\n",
    "        name = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        df[\"start_time\"] = pd.to_timedelta(df[\"start_time\"])\n",
    "        df[\"end_time\"] = pd.to_timedelta(df[\"end_time\"])\n",
    "\n",
    "        silence_df = add_silence(df)\n",
    "\n",
    "        \n",
    "        speaking_sessions = calculate_speaking_sessions(df)\n",
    "        silence_sessions = calculate_speaking_sessions(silence_df)\n",
    "\n",
    "        speaker_sessions_agg = speaking_sessions.groupby('speaker').agg({\n",
    "            'total_time': ['count', \"sum\", \"mean\"],\n",
    "            'total_words': ['sum', \"mean\"],}).reset_index()\n",
    "        \n",
    "        silence_sessions_agg = silence_sessions.groupby('speaker').agg({\n",
    "            'total_time': ['count', \"sum\", \"mean\"]}).reset_index()\n",
    "        \n",
    "        speaker_sessions_agg.columns = ['Speaker', 'Times Spoken', 'Total Speaking Time', \"Average Speaking Time\", 'Number of words', \"Average Number of words\"]\n",
    "        silence_sessions_agg.columns = ['Speaker', 'Times Spoken', 'Total Speaking Time', \"Average Speaking Time\"]\n",
    "\n",
    "        silence_only_sessions_agg = silence_sessions_agg[silence_sessions_agg['Speaker'] == 'Silence'].reset_index(drop=True)\n",
    "\n",
    "        silence_sessions_agg['Percentage of Speaking Time'] = silence_sessions_agg['Total Speaking Time'] / silence_sessions_agg['Total Speaking Time'].sum()\n",
    "\n",
    "        percentage_of_speaking_time = silence_sessions_agg[['Speaker', 'Percentage of Speaking Time']]\n",
    "\n",
    "        share_of_voice = dict()\n",
    "        share_of_voice[\"Call Name\"] = match\n",
    "        share_of_voice[\"Call Number\"]= int(match.split(\"_\")[-1])\n",
    "        date = \"_\".join(match.split(\"_\")[:3])\n",
    "        call_datetime = dt.strptime(date, \"%b_%d_%Y\")\n",
    "        share_of_voice[\"Call Day\"] = call_datetime.strftime(\"%d\")\n",
    "        share_of_voice[\"Call Month\"] = call_datetime.strftime(\"%m\")\n",
    "        share_of_voice[\"Call Year\"] = call_datetime.strftime(\"%Y\")\n",
    "\n",
    "        # print(share_of_voice)\n",
    "\n",
    "        share_of_voice = flatten_categorical_metrics(speaker_sessions_agg , 'Speaker', share_of_voice)\n",
    "        share_of_voice = flatten_categorical_metrics(silence_only_sessions_agg , 'Speaker', share_of_voice)\n",
    "        share_of_voice = flatten_categorical_metrics(percentage_of_speaking_time , 'Speaker', share_of_voice)\n",
    "\n",
    "        metric_columns = list(share_of_voice.keys())[5:]\n",
    "        speaker_set = set()\n",
    "        metric_set = set()\n",
    "\n",
    "        metric_columns = list(share_of_voice.keys())[5:]\n",
    "        speaker_set = set()\n",
    "        metric_set = set()\n",
    "\n",
    "        for column_name in metric_columns:\n",
    "            speaker = column_name.split()[0]\n",
    "            metric = \" \".join(column_name.split()[1:])\n",
    "            speaker_set.add(speaker)\n",
    "            metric_set.add(metric)\n",
    "\n",
    "        speaker_list = sorted(list(speaker_set))\n",
    "        metric_list = sorted(list(metric_set), reverse=True)\n",
    "\n",
    "        column_order = [f\"{speaker} {metric}\" for speaker in speaker_list for metric in metric_list]\n",
    "        column_order = [col for col in column_order if not ('Silence' in col and 'words' in col)]\n",
    "\n",
    "        full_column_order = ['Call Name', 'Call Number', 'Call Day', 'Call Month', 'Call Year'] + column_order\n",
    "\n",
    "        share_of_voice_df = pd.DataFrame(share_of_voice, columns=full_column_order)\n",
    "\n",
    "        share_of_voice_df.to_csv(\n",
    "            f\"{output_relative_path}/{match}_share_of_voice.csv\", index=False\n",
    "        )\n",
    "\n",
    "        print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "869595f4-bb98-43b1-a2ea-9a3dd823912c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Consent Message Delivered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e94085a-bf81-424a-b005-0cccc802d955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_relative_path = f\"{base_path}/06_section/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}07_consent_message_delivered/{folder_path}\"\n",
    "\n",
    "for file_name in sorted(os.listdir(input_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "        with open(f\"{input_relative_path}/{file_name}\", \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        name = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        chunked_text = text_splitter.create_documents([text])\n",
    "        consent_verdict = dict()\n",
    "        consent_verdict[\"Call Name\"] = match\n",
    "        consent_verdict[\"Call Number\"]= int(match.split(\"_\")[-1])\n",
    "        date = \"_\".join(match.split(\"_\")[:3])\n",
    "        call_datetime = dt.strptime(date, \"%b_%d_%Y\")\n",
    "        consent_verdict[\"Call Day\"] = call_datetime.strftime(\"%d\")\n",
    "        consent_verdict[\"Call Month\"] = call_datetime.strftime(\"%m\")\n",
    "        consent_verdict[\"Call Year\"] = call_datetime.strftime(\"%Y\")\n",
    "        total_tokens = 0\n",
    "        prompt_tokens = 0\n",
    "        completion_tokens = 0\n",
    "        successful_requests = 0\n",
    "        total_cost = 0\n",
    "        for i, chunk in enumerate(chunked_text[:1]):\n",
    "            with get_openai_callback() as cb:\n",
    "                output = chat_llm(\n",
    "                    consent_message_delivered.format_messages(text=chunk.page_content)\n",
    "                )\n",
    "\n",
    "            pattern = r\"(Consent) : (True|False)\"\n",
    "            re_match = re.findall(pattern, output.content)[0]\n",
    "\n",
    "            verdict = re_match[1].strip()\n",
    "\n",
    "            if verdict == 'True':\n",
    "                consent_verdict['Consent'] = True\n",
    "            else:\n",
    "                consent_verdict['Consent'] = False\n",
    "\n",
    "            # Costs and Tokens\n",
    "            total_tokens += cb.total_tokens\n",
    "            prompt_tokens += cb.prompt_tokens\n",
    "            completion_tokens += cb.completion_tokens\n",
    "            successful_requests += cb.successful_requests\n",
    "            total_cost += cb.total_cost\n",
    "\n",
    "        df = pd.DataFrame(consent_verdict, index=[0])\n",
    "        df.to_csv(\n",
    "            f\"{output_relative_path}/{match}_consent_verdict.csv\", index=False\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Tokens Used: {total_tokens}, Prompt Tokens: {prompt_tokens}, Completion Tokens: {completion_tokens}, Successful Requests: {successful_requests} \\nTotal Cost (USD): ${round(total_cost, 2)}\"\n",
    "        )\n",
    "\n",
    "        print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4910ff26-73f3-448d-8ced-b8502cfb027d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3684bcb-9c14-4b2d-998d-fe0d527b9693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0.13 seconds\n"
     ]
    }
   ],
   "source": [
    "action_plan_relative_path = f\"{base_path}/07_action_plan_verdict/{folder_path}\"\n",
    "key_topic_relative_path = f\"{base_path}/07_key_topics_conveyed/{folder_path}\"\n",
    "objection_relative_path = f\"{base_path}/07_objection_raised/{folder_path}\"\n",
    "share_of_voice_relative_path = f\"{base_path}/07_share_of_voice/{folder_path}\"\n",
    "output_relative_path = f\"{base_path}/08_results/{folder_path}\"\n",
    "\n",
    "action_plan_combined_df = pd.DataFrame()\n",
    "key_topic_combined_df = pd.DataFrame()\n",
    "objection_combined_df = pd.DataFrame()\n",
    "share_of_voice_combined_df = pd.DataFrame()\n",
    "\n",
    "for file_name in sorted(os.listdir(action_plan_relative_path)):\n",
    "    if any((match := x) in file_name for x in CALL_RECORDINGS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        action_plan_df = pd.read_csv(\n",
    "            f\"{action_plan_relative_path}/{match}_action_plan_verdict.csv\"\n",
    "        )\n",
    "        key_topic_df = pd.read_csv(\n",
    "            f\"{key_topic_relative_path}/{match}_key_topic_count.csv\"\n",
    "        )\n",
    "        objection_df = pd.read_csv(\n",
    "            f\"{objection_relative_path}/{match}_objection_verdict.csv\"\n",
    "        )\n",
    "        share_of_voice_df = pd.read_csv(\n",
    "            f\"{share_of_voice_relative_path}/{match}_share_of_voice.csv\"\n",
    "        )\n",
    "\n",
    "        action_plan_combined_df = pd.concat([action_plan_combined_df, action_plan_df])\n",
    "        key_topic_combined_df = pd.concat([key_topic_combined_df, key_topic_df])\n",
    "        objection_combined_df = pd.concat([objection_combined_df, objection_df])\n",
    "        share_of_voice_combined_df = pd.concat([share_of_voice_combined_df, share_of_voice_df])\n",
    "\n",
    "action_plan_combined_df = action_plan_combined_df.sort_values(by=['Call Month', 'Call Day', 'Call Number'])\n",
    "key_topic_combined_df = key_topic_combined_df.sort_values(by=['Call Month', 'Call Day', 'Call Number'])\n",
    "objection_combined_df = objection_combined_df.sort_values(by=['Call Month', 'Call Day', 'Call Number'])\n",
    "share_of_voice_combined_df = share_of_voice_combined_df.sort_values(by=['Call Month', 'Call Day', 'Call Number'])\n",
    "\n",
    "action_plan_combined_df.to_csv(\n",
    "    f\"{output_relative_path}/action_plan_combined.csv\", index=False\n",
    ")\n",
    "key_topic_combined_df.to_csv(\n",
    "    f\"{output_relative_path}/key_topic_combined.csv\", index=False\n",
    ")\n",
    "objection_combined_df.to_csv(\n",
    "    f\"{output_relative_path}/objection_combined.csv\", index=False\n",
    ")\n",
    "share_of_voice_combined_df.to_csv(\n",
    "    f\"{output_relative_path}/share_of_voice.csv\", index=False\n",
    ")\n",
    "\n",
    "print(f\"Time Taken: {round(time.time() - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3470a42-2579-46f2-95b0-e42ce16e95f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Name</th>\n",
       "      <th>Call Number</th>\n",
       "      <th>Call Day</th>\n",
       "      <th>Call Month</th>\n",
       "      <th>HCP Total Speaking Time</th>\n",
       "      <th>HCP Times Spoken</th>\n",
       "      <th>HCP Percentage of Speaking Time</th>\n",
       "      <th>HCP Number of words</th>\n",
       "      <th>HCP Average Speaking Time</th>\n",
       "      <th>HCP Average Number of words</th>\n",
       "      <th>REP Total Speaking Time</th>\n",
       "      <th>REP Times Spoken</th>\n",
       "      <th>REP Percentage of Speaking Time</th>\n",
       "      <th>REP Number of words</th>\n",
       "      <th>REP Average Speaking Time</th>\n",
       "      <th>REP Average Number of words</th>\n",
       "      <th>Silence Total Speaking Time</th>\n",
       "      <th>Silence Times Spoken</th>\n",
       "      <th>Silence Percentage of Speaking Time</th>\n",
       "      <th>Silence Average Speaking Time</th>\n",
       "      <th>Unknown Total Speaking Time</th>\n",
       "      <th>Unknown Times Spoken</th>\n",
       "      <th>Unknown Percentage of Speaking Time</th>\n",
       "      <th>Unknown Number of words</th>\n",
       "      <th>Unknown Average Speaking Time</th>\n",
       "      <th>Unknown Average Number of words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oct20_callrecording_01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:03:33.990000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.430737</td>\n",
       "      <td>691</td>\n",
       "      <td>0 days 00:00:11.888333333</td>\n",
       "      <td>38.388889</td>\n",
       "      <td>0 days 00:03:28.190000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.419062</td>\n",
       "      <td>698</td>\n",
       "      <td>0 days 00:00:12.246470588</td>\n",
       "      <td>41.058824</td>\n",
       "      <td>0 days 00:01:14.620000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.150201</td>\n",
       "      <td>0 days 00:00:01.963684210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oct20_callrecording_02</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:00:35.720000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>107</td>\n",
       "      <td>0 days 00:00:03.968888888</td>\n",
       "      <td>11.888889</td>\n",
       "      <td>0 days 00:05:06.700000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.845439</td>\n",
       "      <td>952</td>\n",
       "      <td>0 days 00:00:34.077777777</td>\n",
       "      <td>105.777778</td>\n",
       "      <td>0 days 00:00:19.350000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0 days 00:00:01.209375</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct20_callrecording_03</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:01:26.900000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.248669</td>\n",
       "      <td>267</td>\n",
       "      <td>0 days 00:00:07.900000</td>\n",
       "      <td>24.272727</td>\n",
       "      <td>0 days 00:04:12.740000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.723230</td>\n",
       "      <td>734</td>\n",
       "      <td>0 days 00:00:21.061666666</td>\n",
       "      <td>61.166667</td>\n",
       "      <td>0 days 00:00:09.820000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0 days 00:00:00.818333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oct20_callrecording_04</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:03:23.210000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.299159</td>\n",
       "      <td>610</td>\n",
       "      <td>0 days 00:00:16.934166666</td>\n",
       "      <td>50.833333</td>\n",
       "      <td>0 days 00:06:16.950000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.554934</td>\n",
       "      <td>1036</td>\n",
       "      <td>0 days 00:00:28.996153846</td>\n",
       "      <td>79.692308</td>\n",
       "      <td>0 days 00:01:39.110000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0 days 00:00:01.651833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oct20_callrecording_05</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:21:40.690000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.495250</td>\n",
       "      <td>4431</td>\n",
       "      <td>0 days 00:00:17.114342105</td>\n",
       "      <td>58.302632</td>\n",
       "      <td>0 days 00:16:02.170000</td>\n",
       "      <td>78</td>\n",
       "      <td>0.366355</td>\n",
       "      <td>3155</td>\n",
       "      <td>0 days 00:00:12.335512820</td>\n",
       "      <td>40.448718</td>\n",
       "      <td>0 days 00:05:58.990000</td>\n",
       "      <td>228</td>\n",
       "      <td>0.136689</td>\n",
       "      <td>0 days 00:00:01.574517543</td>\n",
       "      <td>0 days 00:00:04.480000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0 days 00:00:01.120000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Oct20_callrecording_07</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:06:58.760000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.256046</td>\n",
       "      <td>1310</td>\n",
       "      <td>0 days 00:00:16.106153846</td>\n",
       "      <td>50.384615</td>\n",
       "      <td>0 days 00:16:16.780000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.597240</td>\n",
       "      <td>2854</td>\n",
       "      <td>0 days 00:00:40.699166666</td>\n",
       "      <td>118.916667</td>\n",
       "      <td>0 days 00:03:58.130000</td>\n",
       "      <td>124</td>\n",
       "      <td>0.145602</td>\n",
       "      <td>0 days 00:00:01.920403225</td>\n",
       "      <td>0 days 00:00:01.820000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0 days 00:00:00.910000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oct20_callrecording_08</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:00:50.660000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.100363</td>\n",
       "      <td>158</td>\n",
       "      <td>0 days 00:00:02.980000</td>\n",
       "      <td>9.294118</td>\n",
       "      <td>0 days 00:06:48.100000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.808487</td>\n",
       "      <td>1151</td>\n",
       "      <td>0 days 00:00:22.672222222</td>\n",
       "      <td>63.944444</td>\n",
       "      <td>0 days 00:00:46.010000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.091150</td>\n",
       "      <td>0 days 00:00:01.122195121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oct20_callrecording_09</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:00:33.770000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.107627</td>\n",
       "      <td>119</td>\n",
       "      <td>0 days 00:00:04.824285714</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0 days 00:04:24.550000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843134</td>\n",
       "      <td>750</td>\n",
       "      <td>0 days 00:00:33.068750</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>0 days 00:00:15.450000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.049240</td>\n",
       "      <td>0 days 00:00:00.965625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oct20_callrecording_10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:12:37.030000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.633291</td>\n",
       "      <td>2152</td>\n",
       "      <td>0 days 00:00:19.411025641</td>\n",
       "      <td>55.179487</td>\n",
       "      <td>0 days 00:03:05.720000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.155364</td>\n",
       "      <td>620</td>\n",
       "      <td>0 days 00:00:04.887368421</td>\n",
       "      <td>16.315789</td>\n",
       "      <td>0 days 00:04:12.220000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.210994</td>\n",
       "      <td>0 days 00:00:02.017760</td>\n",
       "      <td>0 days 00:00:00.420000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:00.420000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct20_callrecording_11</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:10:58.760000</td>\n",
       "      <td>61</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>2099</td>\n",
       "      <td>0 days 00:00:10.799344262</td>\n",
       "      <td>34.409836</td>\n",
       "      <td>0 days 00:11:56.100000</td>\n",
       "      <td>58</td>\n",
       "      <td>0.430405</td>\n",
       "      <td>2202</td>\n",
       "      <td>0 days 00:00:12.346551724</td>\n",
       "      <td>37.965517</td>\n",
       "      <td>0 days 00:04:43.750000</td>\n",
       "      <td>166</td>\n",
       "      <td>0.170545</td>\n",
       "      <td>0 days 00:00:01.709337349</td>\n",
       "      <td>0 days 00:00:05.170000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0 days 00:00:01.292500</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oct20_callrecording_12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0 days 00:00:31.780000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.077671</td>\n",
       "      <td>77</td>\n",
       "      <td>0 days 00:00:02.648333333</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>0 days 00:04:28.190000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.655465</td>\n",
       "      <td>766</td>\n",
       "      <td>0 days 00:00:20.630000</td>\n",
       "      <td>58.923077</td>\n",
       "      <td>0 days 00:01:49.190000</td>\n",
       "      <td>57</td>\n",
       "      <td>0.266864</td>\n",
       "      <td>0 days 00:00:01.915614035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Call Name</th>\n      <th>Call Number</th>\n      <th>Call Day</th>\n      <th>Call Month</th>\n      <th>HCP Total Speaking Time</th>\n      <th>HCP Times Spoken</th>\n      <th>HCP Percentage of Speaking Time</th>\n      <th>HCP Number of words</th>\n      <th>HCP Average Speaking Time</th>\n      <th>HCP Average Number of words</th>\n      <th>REP Total Speaking Time</th>\n      <th>REP Times Spoken</th>\n      <th>REP Percentage of Speaking Time</th>\n      <th>REP Number of words</th>\n      <th>REP Average Speaking Time</th>\n      <th>REP Average Number of words</th>\n      <th>Silence Total Speaking Time</th>\n      <th>Silence Times Spoken</th>\n      <th>Silence Percentage of Speaking Time</th>\n      <th>Silence Average Speaking Time</th>\n      <th>Unknown Total Speaking Time</th>\n      <th>Unknown Times Spoken</th>\n      <th>Unknown Percentage of Speaking Time</th>\n      <th>Unknown Number of words</th>\n      <th>Unknown Average Speaking Time</th>\n      <th>Unknown Average Number of words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oct20_callrecording_01</td>\n      <td>1</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:03:33.990000</td>\n      <td>18</td>\n      <td>0.430737</td>\n      <td>691</td>\n      <td>0 days 00:00:11.888333333</td>\n      <td>38.388889</td>\n      <td>0 days 00:03:28.190000</td>\n      <td>17</td>\n      <td>0.419062</td>\n      <td>698</td>\n      <td>0 days 00:00:12.246470588</td>\n      <td>41.058824</td>\n      <td>0 days 00:01:14.620000</td>\n      <td>38</td>\n      <td>0.150201</td>\n      <td>0 days 00:00:01.963684210</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oct20_callrecording_02</td>\n      <td>2</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:00:35.720000</td>\n      <td>9</td>\n      <td>0.098465</td>\n      <td>107</td>\n      <td>0 days 00:00:03.968888888</td>\n      <td>11.888889</td>\n      <td>0 days 00:05:06.700000</td>\n      <td>9</td>\n      <td>0.845439</td>\n      <td>952</td>\n      <td>0 days 00:00:34.077777777</td>\n      <td>105.777778</td>\n      <td>0 days 00:00:19.350000</td>\n      <td>16</td>\n      <td>0.053340</td>\n      <td>0 days 00:00:01.209375</td>\n      <td>0 days 00:00:01</td>\n      <td>1.0</td>\n      <td>0.002757</td>\n      <td>7.0</td>\n      <td>0 days 00:00:01</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Oct20_callrecording_03</td>\n      <td>3</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:01:26.900000</td>\n      <td>11</td>\n      <td>0.248669</td>\n      <td>267</td>\n      <td>0 days 00:00:07.900000</td>\n      <td>24.272727</td>\n      <td>0 days 00:04:12.740000</td>\n      <td>12</td>\n      <td>0.723230</td>\n      <td>734</td>\n      <td>0 days 00:00:21.061666666</td>\n      <td>61.166667</td>\n      <td>0 days 00:00:09.820000</td>\n      <td>12</td>\n      <td>0.028100</td>\n      <td>0 days 00:00:00.818333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Oct20_callrecording_04</td>\n      <td>4</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:03:23.210000</td>\n      <td>12</td>\n      <td>0.299159</td>\n      <td>610</td>\n      <td>0 days 00:00:16.934166666</td>\n      <td>50.833333</td>\n      <td>0 days 00:06:16.950000</td>\n      <td>13</td>\n      <td>0.554934</td>\n      <td>1036</td>\n      <td>0 days 00:00:28.996153846</td>\n      <td>79.692308</td>\n      <td>0 days 00:01:39.110000</td>\n      <td>60</td>\n      <td>0.145907</td>\n      <td>0 days 00:00:01.651833333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oct20_callrecording_05</td>\n      <td>5</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:21:40.690000</td>\n      <td>76</td>\n      <td>0.495250</td>\n      <td>4431</td>\n      <td>0 days 00:00:17.114342105</td>\n      <td>58.302632</td>\n      <td>0 days 00:16:02.170000</td>\n      <td>78</td>\n      <td>0.366355</td>\n      <td>3155</td>\n      <td>0 days 00:00:12.335512820</td>\n      <td>40.448718</td>\n      <td>0 days 00:05:58.990000</td>\n      <td>228</td>\n      <td>0.136689</td>\n      <td>0 days 00:00:01.574517543</td>\n      <td>0 days 00:00:04.480000</td>\n      <td>4.0</td>\n      <td>0.001706</td>\n      <td>16.0</td>\n      <td>0 days 00:00:01.120000</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Oct20_callrecording_07</td>\n      <td>7</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:06:58.760000</td>\n      <td>26</td>\n      <td>0.256046</td>\n      <td>1310</td>\n      <td>0 days 00:00:16.106153846</td>\n      <td>50.384615</td>\n      <td>0 days 00:16:16.780000</td>\n      <td>24</td>\n      <td>0.597240</td>\n      <td>2854</td>\n      <td>0 days 00:00:40.699166666</td>\n      <td>118.916667</td>\n      <td>0 days 00:03:58.130000</td>\n      <td>124</td>\n      <td>0.145602</td>\n      <td>0 days 00:00:01.920403225</td>\n      <td>0 days 00:00:01.820000</td>\n      <td>2.0</td>\n      <td>0.001113</td>\n      <td>4.0</td>\n      <td>0 days 00:00:00.910000</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oct20_callrecording_08</td>\n      <td>8</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:00:50.660000</td>\n      <td>17</td>\n      <td>0.100363</td>\n      <td>158</td>\n      <td>0 days 00:00:02.980000</td>\n      <td>9.294118</td>\n      <td>0 days 00:06:48.100000</td>\n      <td>18</td>\n      <td>0.808487</td>\n      <td>1151</td>\n      <td>0 days 00:00:22.672222222</td>\n      <td>63.944444</td>\n      <td>0 days 00:00:46.010000</td>\n      <td>41</td>\n      <td>0.091150</td>\n      <td>0 days 00:00:01.122195121</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Oct20_callrecording_09</td>\n      <td>9</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:00:33.770000</td>\n      <td>7</td>\n      <td>0.107627</td>\n      <td>119</td>\n      <td>0 days 00:00:04.824285714</td>\n      <td>17.000000</td>\n      <td>0 days 00:04:24.550000</td>\n      <td>8</td>\n      <td>0.843134</td>\n      <td>750</td>\n      <td>0 days 00:00:33.068750</td>\n      <td>93.750000</td>\n      <td>0 days 00:00:15.450000</td>\n      <td>16</td>\n      <td>0.049240</td>\n      <td>0 days 00:00:00.965625</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Oct20_callrecording_10</td>\n      <td>10</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:12:37.030000</td>\n      <td>39</td>\n      <td>0.633291</td>\n      <td>2152</td>\n      <td>0 days 00:00:19.411025641</td>\n      <td>55.179487</td>\n      <td>0 days 00:03:05.720000</td>\n      <td>38</td>\n      <td>0.155364</td>\n      <td>620</td>\n      <td>0 days 00:00:04.887368421</td>\n      <td>16.315789</td>\n      <td>0 days 00:04:12.220000</td>\n      <td>125</td>\n      <td>0.210994</td>\n      <td>0 days 00:00:02.017760</td>\n      <td>0 days 00:00:00.420000</td>\n      <td>1.0</td>\n      <td>0.000351</td>\n      <td>1.0</td>\n      <td>0 days 00:00:00.420000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Oct20_callrecording_11</td>\n      <td>11</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:10:58.760000</td>\n      <td>61</td>\n      <td>0.395942</td>\n      <td>2099</td>\n      <td>0 days 00:00:10.799344262</td>\n      <td>34.409836</td>\n      <td>0 days 00:11:56.100000</td>\n      <td>58</td>\n      <td>0.430405</td>\n      <td>2202</td>\n      <td>0 days 00:00:12.346551724</td>\n      <td>37.965517</td>\n      <td>0 days 00:04:43.750000</td>\n      <td>166</td>\n      <td>0.170545</td>\n      <td>0 days 00:00:01.709337349</td>\n      <td>0 days 00:00:05.170000</td>\n      <td>4.0</td>\n      <td>0.003107</td>\n      <td>12.0</td>\n      <td>0 days 00:00:01.292500</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Oct20_callrecording_12</td>\n      <td>12</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0 days 00:00:31.780000</td>\n      <td>12</td>\n      <td>0.077671</td>\n      <td>77</td>\n      <td>0 days 00:00:02.648333333</td>\n      <td>6.416667</td>\n      <td>0 days 00:04:28.190000</td>\n      <td>13</td>\n      <td>0.655465</td>\n      <td>766</td>\n      <td>0 days 00:00:20.630000</td>\n      <td>58.923077</td>\n      <td>0 days 00:01:49.190000</td>\n      <td>57</td>\n      <td>0.266864</td>\n      <td>0 days 00:00:01.915614035</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv(f\"{output_relative_path}/share_of_voice.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03_Analysing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
